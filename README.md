# 个性化推荐
## 1.数据预处理

采用**python**的**scipy.sparse**模块来存储训练数据矩阵与测试矩阵，在读取文件并初始化矩阵时，利用用户id文件，使得训练矩阵与测试矩阵中相同行对应的用户是相同的，同一列对应的电影是一致的，便于后续处理。对于未打分的项，直接将其置零。在实验中选择全量数据进行处理，并将数据保存为npz文件形式，便于后续的实验读取数据。

## 2.协同滤波

根据文档所述，可以将评分写为：
$$
score(i,j)=sim^T_i \cdot score(:, j)
$$
其中：
$$
\begin{align}
sim_{i,j}'=\left[\begin{matrix}
sim(X(i), X(1)) & sim(X(i), X(2)),...,sim(X(i), X(N))
\end{matrix}\right]^T
\end{align}
$$
而$sim_i$则是在$sim_i'$的基础上，将$sim(X(i), X(i))$以及所有未给电影$j$打分的用户$i$设为0，即：
$$
\begin{align}
sim_{i,j}(k)&=0 &score(k, j)= 0\or k=i 
\end{align}
$$
且只保留前k大的相似度的向量，即只**取与用户最相似的k个用户**的打分进行加权求和，在代码中采用的是**cosine**相似度。为了避免重复计算，提前计算相似度矩阵$sim=(sim(X(i), X(j)))_{i, j}$，由于在对计算用户$i$对电影$j$的评分时，需要计算最近邻，故而难以进一步优化为矩阵乘法形式，只能对测试矩阵中的每个非0项进行循环，每次循环时计算：

- 提取用户$i$对应的相似度向量$sim_{i,j}'$
- 将未评分的用户$k$以及用户$i$的相似度置零
- 计算K近邻并保留其对应相似度，归一化后得到$sim_{i,j}$
- 计算$score(i,j)$

在算法中，最近邻数目$K$为超参数，通过选取不同的$K$进行实验，得到$RMSE$以及每次算法耗时如下：

| K      | 10    | 50    | 100   | 200   | 500   | 1000  | 2000  | 随机算法 |
| ------ | ----- | ----- | ----- | ----- | ----- | ----- | ----- | -------- |
| RMSE   | 0.981 | 0.962 | 0.966 | 0.972 | 0.982 | 0.991 | 1.002 | 1.836    |
| time/s | 521   | 534   | 532   | 524   | 527   | 540   | 555   |          |

其中$RMSE=\sqrt{\frac{1}{|TEST|}\sum _{i, j}(X_{i,j}-\hat X_{i,j})^2}$，其中$|TEST|$为测试集非0项个数。由于实际打分取值1到5，可以得知$RMSE$最大不会超过4，多次平均随机算法的RMSE可以得到其baseline为1.836。可以看出在选取k在$[50,100]$范围时，可以获取最佳的$RMSE$指标。

## 3.矩阵分解

矩阵分解采用文档中给出的公式进行迭代：
$$
U=(1-2\lambda\alpha)U+\alpha(A\bigodot(X-UV^T))V\\
V =(1-2\lambda\alpha)V+\alpha(A\bigodot(X-UV^T))U
$$
此外，为了更好地优化参数，考虑对学习率$\alpha$进行动态调整，具体策略为：

- 计算梯度，得到更新后的分解矩阵$U_2=U-\alpha\frac{\part J}{\part U}$，$V_2=V-\alpha\frac{\part V}{\part V}$。
- 对比$J(U,V,X)$与$J(U_2,V_2,X)$，若更新后的loss小，则$U\leftarrow U_2,V\leftarrow V_2$
- 否则不对$U,V$进行更新，$\alpha \leftarrow \alpha / 10$

迭代停止条件为达到最大的迭代次数，由于计算中$UV^T$并不是稀疏矩阵，故而此次计算直接采用python的**numpy.ndarray**。除此之外，经过实验，发现$U,V$的初始化也十分重要，否则很容易出现梯度爆炸以及迭代次数很多，loss却还是很大的问题。对$U,V$赋予较小的值，有利于后续的优化算法。故而对$U,V$的初始化策略为：$U,V$每个值赋予$[\frac{-0.1}{\sqrt{k}}, \frac{0.1}{\sqrt{k}}]$区间内均匀分布的随机数。



